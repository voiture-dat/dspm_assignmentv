---
title: "Assignment 5 - Max Haberl"
date: "07/02/2020"
output:
  html_document:
    toc: True
author: Max Haberl (5407084) in collaboration with Lukas Guenner (5393972) (different codes)

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Assignment 5 - GitHub and the ticketmaster.com API
I hereby assure to have complied with the *Code of Conduct*


**Please  Note:** Copy the path of your directory including the datasets to the clipboard. The *wd()* function will paste it coherently to the working directory

```{r Preparation, echo = FALSE, error = TRUE}

# Example of the path I used and copied into the clipboard C:\Users\maxem\Documents\Uni\Master\WiSe 2021\DSPM 20\Assignments\Ass5\Repo
rm(list= ls()) # clearing workspace
wd <- function() {  # helps converting a copied file path into r-eligible strings, otherwise directly assign to path
  x <- readClipboard()
  x <- gsub("\\\\", "/", x)
  return(x)
  }
path <- wd() # sets path according to wd() fct
# path <- "YOUR_WORKING_PATH"
setwd(path)
getwd()
```

## Exercise 1 & 2 - Setting things up

Request API key via [ticketmaster explorer](https://developer.ticketmaster.com/api-explorer/v2/) and setup repository on [github.com/voiture-dat/dspm_assignmentv](https://github.com/voiture-dat/dspm_assignmentv)


Loading the data, merging and preprocessing as required.
```{r EX1}
source("../../tm_api_key.R")
# otherwise use your own key
# app_key <- 'XXXXXXXXXXXXXXXXXXX'

```



## Exercise 3 

At first we retrieve nested data iin that the json object contains the data of interest as well as some meta data on our search request. within the first sublist all required information is nested into lists again. In order to disentangle the embedded information some intermediate steps are necessary as can be seen below. Caveat: one API call only delivers 20 entries, meaning that we have to loop through the pages in order to retrieve all venues Germany-wide.

``` {r EX 3, warning = FALSE}
if (!require("httr")) install.packages("httr")
if (!require("dplyr")) install.packages("dplyr")

if (!require("jsonlite")) install.packages("jsonlite")
library(httr)
library(jsonlite)
library(dplyr)

query_list <- paste('https://app.ticketmaster.com/discovery/v2/venues?apikey=', app_key ,'&locale=*&page=0&countryCode=DE', sep = "")

# Germany:
retr <- GET(query_list)
cont <- fromJSON(content(retr, as = 'text'))
venue_data <- as.data.frame(cont$`_embedded`$venues)
venue_data_DE <- data.frame(venue_data$name, venue_data$city[1], venue_data$postalCode, venue_data$address[1], venue_data$url, venue_data$location[1], venue_data$location[2])
colnames(venue_data_DE) <- c('name', 'city', 'postalCode', 'address', 'url', 'longitude', 'latitude')


```

## Exercise 4 - Loop through pages



``` {r EX 4, warning = FALSE, message = FALSE}

num_pages <- cont$page$totalPages
num_entries <- cont$page$totalElements


# iterate over all pages and store in large list object
cont_list <- vector(mode = 'list', length = num_pages)
for (i in 0:(num_pages-1)){
  query_list2 <- paste('https://app.ticketmaster.com/discovery/v2/venues?apikey=', app_key ,'&locale=*&page=',i,'&countryCode=DE', sep = "")
  temp_retr <- GET(query_list2)
  temp_cont <- fromJSON(content(temp_retr, as = 'text'))
  cont_list[i+1] <- temp_cont
  Sys.sleep(0.2) # throws errors anyways, even with more conservative rates, API instable? Throws errors even for 1 per second...
  
}

df <- as.data.frame(cont_list[1])

for (i in 2:num_pages){
  tryCatch({
    df2 <- as.data.frame(cont_list[i])
    df <- full_join(df, df2)    
  }, error = function(e){})

}
venue_data_all <- data.frame(df$venues.name, df$venues.city[1], df$venues.postalCode, df$venues.address[1], df$venues.url, df$venues.location[1], df$venues.location[2])

library(tidyr)
venue_data_all <- drop_na(venue_data_all)
venue_data_all$longitude <- as.numeric(venue_data_all$longitude)
venue_data_all$latitude <- as.numeric(venue_data_all$latitude)
venue_data_all <- subset(venue_data_all, (venue_data_all$longitude < 15.043611 & venue_data_all$longitude > 5.866944) & (venue_data_all$latitude < 55.0846 & venue_data_all$latitude > 47.271679))




```

## Exercise 5 - Visualisation
``` {r EX 5, warning = FALSE, message = FALSE}
library(ggplot2)
ggplot() +
  geom_polygon(
    aes(x = long, y = lat, group = group), data = map_data("world", region = "Germany"), fill = "grey90",color = "black") +
  theme_void() + coord_quickmap() +
  geom_point(aes(x = longitude, y = latitude), data = venue_data_all, color = 'red', alpha = 0.2) + 
  labs(title = "Event locations across Germany", caption = "Source: ticketmaster.com") +
  theme(title = element_text(size=8, face='bold'), plot.caption = element_text(face = "italic"))

# ggsave('venues_GER.jpeg', path = './figures') # for saving to figures folder

```

## Exercise 6 - Repeat for Netherlands

``` {r EX 6, warning = FALSE, message = FALSE}

query_list <- paste('https://app.ticketmaster.com/discovery/v2/venues?apikey=', app_key ,'&locale=*&page=0&countryCode=NL', sep = "")

# Germany:
retr <- GET(query_list)
cont <- fromJSON(content(retr, as = 'text'))
num_pages <- cont$page$totalPages

# venue_data_all <- data.frame(matrix(NA, nrow = 0, ncol = 7))
# colnames(venue_data_all) <- c('name', 'city', 'postalCode', 'address', 'url', 'longitude', 'latitude')

cont_list <- vector(mode = 'list', length = num_pages)
for (i in 0:(num_pages-1)){
  query_list2 <- paste('https://app.ticketmaster.com/discovery/v2/venues?apikey=', app_key ,'&locale=*&page=',i,'&countryCode=NL', sep = "")
  temp_retr <- GET(query_list2)
  temp_cont <- fromJSON(content(temp_retr, as = 'text'))
  cont_list[i+1] <- temp_cont
  Sys.sleep(0.2) # throws errors anyways, even with more conservative rates
  
}

df_NL <- as.data.frame(cont_list[1])

for (i in 2:num_pages){
  tryCatch({
    df2 <- as.data.frame(cont_list[i])
    df_NL <- full_join(df_NL, df2)    
  }, error = function(e){})

}
venue_data_all_NL <- data.frame(df_NL$venues.name, df_NL$venues.city[1], df_NL$venues.postalCode, df_NL$venues.address[1], df_NL$venues.url, df_NL$venues.location[1], df_NL$venues.location[2])


venue_data_all_NL <- drop_na(venue_data_all_NL)
venue_data_all_NL$longitude <- as.numeric(venue_data_all_NL$longitude)
venue_data_all_NL$latitude <- as.numeric(venue_data_all_NL$latitude)
venue_data_all_NL <- subset(venue_data_all_NL, (venue_data_all_NL$longitude < 7.2277 & venue_data_all_NL$longitude > 3.3583) & (venue_data_all_NL$latitude < 53.555 & venue_data_all_NL$latitude > 50.750417))


ggplot() +
  geom_polygon(
    aes(x = long, y = lat, group = group), data = map_data("world", region = "Netherlands"), fill = "grey90",color = "black") +
  theme_void() + coord_quickmap() +
  geom_point(aes(x = longitude, y = latitude), data = venue_data_all_NL, color = 'red', alpha = 0.2) + 
  labs(title = "Event locations across the Netherlands", caption = "Source: ticketmaster.com") +
  theme(title = element_text(size=8, face='bold'), plot.caption = element_text(face = "italic"))

#ggsave('venues_NL.jpeg', path = './figures') # for saving to figures folder


```